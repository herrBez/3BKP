\section{Performance}
\label{sec:benchmark}
Per testare le performance del modello proposto in Baldi et. 
al~\cite{Baldi20129802} e le estensioni fornite
in questo documento sono state generate varie istanze casuali.
Per motivi di tempo non sono stati considerati i Balancing Constraints. 

Con uno script python \path{instance_generator.py}, sono state create varie
istanze casuali: cinque per ogni 
combinazione di $k = \{1,5,10,15\}$ e $j = \{10,15,20,30,40\}$. 

Il computer usato per le simulazioni ha 8GB di RAM (DDR3) un processore 
Intel(R) Core(TM) i7-3610QM CPU @ 2.30GHz del 2012~\cite{cpu}.
Il sistema operativo usato per le simulazione è openSUSE 13.2 (Harlequin) con
il kernel linux 3.16.7-24-desktop.

Per permettere delle analisi agevoli con \verb|R| è stata aggiunta un'opzione di
\verb|--benchmark| all'interno dei vari programmi. 
Questa opzione formatta l'output per contenere in una riga le seguenti 
informazioni: User Time, CPU Time, Objective Value, Timeout Reached (Yes/No).

Per rendere automatica l'esecuzione dei vari programmi è stato scritto uno 
script in bash \path{benchmark.sh}. 
All'inizio del file possono essere specificati i seguenti parametri:
\begin{itemize}
\item il programma da usare, 
\item il numero di esecuzioni per istanza: in questo documento sono stati usati
5 test per motivi di tempo,
\item la cartella dove trovare le istanze, 
\item una regex per i file da eseguire  (per esempio \verb|10*.dat| per eseguire
 tutti i file che cominciano con 10), 
\item secondi di pausa dopo l'esecuzione di un programma,
\item suffisso da dare ai file \verb|.csv| generati dal programma
\item il timeout dopo il quale stoppare l'esecuzione.
Per questi test è stato usato come timeout $6300$ secondi di CPU. Questo valore
è stato ottenuto moltiplicando $15$ minuti per $7$, che sembrava essere
circa il parallelismo che riusciva a raggiungere CPLEX nei primi esempi eseguiti.
È stato preferito il tempo di CPU a quello utente perchè è meno dipendente dalle
politiche di scheduling del sistema operativo sottostante.
Visto che per settare il timeout è stata usata una funzione interna a CPLEX, il timeout
effettivo non è sempre lo stesso, come dimostrano le tabelle dell'Appendice \ref{sec:results}.
Il tempo di CPU è stato comunque riportato nelle istanze in cui il timeout era 
stato raggiunto per valutare il livello di parallelismo 
raggiunto da CPLEX.
\end{itemize}

I file di input per il benchmark si possono trovare nella cartella \path{Instances}.
Al suo interno possono essere trovate $4$ sottocartelle: \path{OneKnapsack}, 
\path{FiveKnapsacks}, \path{TenKnapsacks} e \path{FifteenKnapsacks}.
I risultati dei benchmark grezzi possono essere trovati nella cartella 
\path{Benchmark}. Nell'appendice  \ref{sec:results} vengono riportati delle
elaborazioni sotto forma tabellare.
Il significato delle varie colonne è riportato nella Tabella \ref{table:description}.

Purtroppo per le istanze in cui si è raggiunto il timeout non si hanno dati
sulla soluzione ottima e quindi non si possono 
fare stime sul livello di accuratezza delle soluzioni incombenti.
Viene quindi solo riportato il coefficiente di variazione per gli
objective values. Naturalmente 
per i problemi risolti sempre con successo questo coefficiente è pari a $0$.

\begin{table}
\centering
\small
\begin{tabular}{| l| l |}
\hline
Abbreviazione & Descrizione \\
\hline
inst. & Nome dell'istanza \\
done & Numero di esecuzioni completate con successo prima del timeout\\
AUT & Average user time in minuti \\
ACT & Average CPU time in minuti\\
CU  & CPU usage: numero di cpu usate in media per eseguire l'istanza: \\
	& è ottenuto come $AUT/ACT$\\
max & Max CPU time \\
min & Min CPU time \\
CV-T & coefficiente di variazione per il tempo di CPU \\
ObjV & media del valore della funzione obiettivo. Nel caso di soluzioni ottime \\
	& corrisponde al risultato della soluzione ottima.\\
CV-O & coefficiente di variazioni per i valori della funzione obiettivo. In caso \\
& di solo soluzioni ottime questo valore è $0$. \\
\hline
\end{tabular}
\caption{Descizione dei significati delle colonne usate per riportare i dati
di benchmark.}
\label{table:description}
\end{table}


\subsection{Breve Commento sui risultati}



\paragraph{3BKP}
Il programma \emph{3BKP} risulta risolvibile entro i limiti stabiliti ($6300$ secondi di cpu)
per le istanze fino a 20 elementi compresi. L'istanza \verb|30_3| risulta
essere risolta in poco tempo. Probabilmente questa anomalia è dovuta alla
scelta casuale delle istanze.

\paragraph{Multi3BKP}
In generale il programma \path{Multi3BKP} non riesce a risolvere nel timeout
stabilito nessuna istanza con $40$ e $30$ elementi (c'è solo la stessa eccezione
di \path{3BKP}). 
In generale si possono notare numerose istanze in cui l'objective value in tutte
e $5$ le istanze è uguale ma è stato raggiunto il timeout. Alcune di queste
soluzioni probabilmente sono soluzioni ottime.


\paragraph{SmallHull}
Tutte le istanze con $20$ elementi non state portate a termine entro ai limiti
stabiliti, mentre le istanze con $15$ elementi risultano risolvibili fino a
$K = 5$. 
Superato $K = 1$ perfino alcune istanze con $10$ elementi non risultano più risultano
più risolvibili nei tempi stabiliti.

Nelle Tabelle \ref{table:hull:10} e \ref{table:hull:15} si possono notare
anche due istanze che hanno portato  il kernel a stoppare il processo CPLEX,
per avere richiesto troppa memoria. 

\paragraph{Stabilità di CPLEX}
CPLEX risulta avere delle performance molto stabili come mostrano le colonne
CV-T e CV-O delle tabelle dell'Appendice \ref{sec:results}.

\paragraph{Altre considerazioni}
Molte istanze, nonostante non siano state portate effettivamente a termine nei
limiti stabiliti, hanno objective values con deviazioni standard uguali a $0$.
Non è escluso che parte di esse possa essere una soluzione ottima.




\subsection{Problema Accessorio}
\label{sec:benchmark:accessorio}
Questa Sezione ha il solo scopo di fornire dei dati per supportare l'affermazione
fatta nella Sezione \ref{sec:multi:problemaAcessorio}, ovvero che c'è una 
differenza  considerevole di tempo necessario e qualità della soluzione se 
vengono fissate 
tutte le variabili (eccetto le $\chi$) o se si evita di fissare le variabili
$b$.

Per motivi di tempo questo test è stato fatto \emph{solo} per poche istanze.
I risultati si possono trovare nella Tabella \ref{table:accessorio:res}.

I pochi dati forniti mostrano chiaramente che fissando le variabili $b$ del problema
il tempo richiesto per risolverlo cresce notevolmente. Ma al contempo la qualità
delle soluzioni cresce considerevolmente.

Per motivi di spazio nella Tabella \ref{table:accessorio:res} il problema con
le variabile \emph{fissate} è stato abbreviato con F, mentre quello con le
variabili \emph{non fissate} è stato abbreviato con NF.
SOV indica lo start objective
value, ovvero il valore di partenza della somma delle $\chi$ prima di risolvere
il problema accessorio.
Di seguito vengono riportati l'objective value di F e l'objective value di NF 
O-Impr indica la percentuale di miglioramento nell'objective value risolvendo
il problema NF invece che F. 
ACT F e ACT NF indicano l'average CPU time del problema per il problema F
e il problema NF. Infine Diff indica quanto tempo
in più (in percentuale) ci ha messo NF rispetto a F.


\begin{table}[h!]
\begin{center}
\small
\begin{tabular}{| c | c | c | c | c | c | c | c | c | }
\hline
inst.			& SOV	& OF				& ONF 				& O-Impr. 	& ACT F 	& ACT NF 		& Diff \\
\hline
\verb|5_10_1|	& 3144  	& 2956	(-5.98\%) 	& 2127 	(-32.34\%)	& -28.04\%	 			& 0.00542 	& 0.07414 	& +92\% \\ 
\verb|5_10_2|	& 3999		& 3700	(-7.47\%)	& 1404	(-64.89\%)	& -62.05\%				& 0.00594	& 0.06318 		& +90.7\%\\
\verb|5_10_3|	& 7835		& 7467	(-4.70\%)	& 3225	(-58.83\%)	& -56.80\%				& 0.00526	& 1.835 		& +98.5\% \\

\hline
\end{tabular}
\caption{Risultati per il problema accessorio.}
\label{table:accessorio:res}
\end{center}
\end{table}
